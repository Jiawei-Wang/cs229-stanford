"""
1. Linear regression
2. batch and stochastic gradient descent
3. normal equations


process: training data -> learning algorithm -> hypothesis
question: how to present the hypothesis

Gradient descent/Local optimum/learning rate   
Bash Gradient Descent/stochastic gradient descent: SGD allows to train faster on large data set but produces noises and never stops at global optimum
 """